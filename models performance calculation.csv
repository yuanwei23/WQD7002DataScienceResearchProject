Scenario 1: All Questions,,,,,,,,,,,,,,
,Model,Accuracy,Precision,Recall,F1 Score,Average,,,Model,Scenario,Performance (%),,,
1,AdaBoost,0.54,0.65,0.54,0.54,0.57,,,Gradient Boosting,1,67%,,,
2,Bagging Classifier,0.70,0.68,0.70,0.69,0.69,,,Gradient Boosting,2,74%,,,
3,Decision Tree,0.48,0.51,0.48,0.49,0.49,,,Gradient Boosting,3,49%,,,
4,Gradient Boosting,0.68,0.66,0.68,0.67,0.67,,,Gradient Boosting,4,63%,,,
5,k-Nearest Neighbors,0.62,0.62,0.62,0.61,0.62,,,Gradient Boosting,5,75%,,,
6,Logistic Regression,0.66,0.69,0.66,0.66,0.67,,,k-Nearest Neighbors,1,62%,,,
7,Naïve Bayes,0.22,0.32,0.22,0.11,0.22,,,k-Nearest Neighbors,2,76%,,,
8,Neural Network,0.58,0.59,0.58,0.57,0.58,,,k-Nearest Neighbors,3,52%,,,
9,Random Forest,0.70,0.67,0.70,0.67,0.68,,,k-Nearest Neighbors,4,71%,,,
10,Support Vector Machine,0.72,0.69,0.72,0.70,0.71,,,k-Nearest Neighbors,5,73%,,,
,,,,,,,,,Logistic Regression,1,67%,,,
Scenario 2: Average Responses Group Columns,,,,,,,,,Logistic Regression,2,72%,,,
,Model,Accuracy,Precision,Recall,F1 Score,Average,,,Logistic Regression,3,61%,,,
1,AdaBoost,0.68,0.57,0.68,0.61,0.63,,,Logistic Regression,4,63%,,,
2,Bagging Classifier,0.72,0.73,0.72,0.72,0.72,,,Logistic Regression,5,70%,,,
3,Decision Tree,0.62,0.61,0.62,0.60,0.61,,,Support Vector Machine,1,71%,,,
4,Gradient Boosting,0.74,0.76,0.74,0.74,0.74,,,Support Vector Machine,2,71%,,,
5,k-Nearest Neighbors,0.76,0.77,0.76,0.76,0.76,,,Support Vector Machine,3,60%,,,
6,Logistic Regression,0.72,0.71,0.72,0.71,0.72,,,Support Vector Machine,4,68%,,,
7,Naïve Bayes,0.20,0.04,0.20,0.07,0.13,,,Support Vector Machine,5,67%,,,
8,Neural Network,0.74,0.72,0.74,0.73,0.73,,,,,,,,
9,Random Forest,0.66,0.67,0.66,0.66,0.66,,,,,,,,
10,Support Vector Machine,0.72,0.69,0.72,0.70,0.71,,,,,,,,
,,,,,,,,,,,,,,
Scenario 3: Usability Columns,,,,,,,,,,,,,,
,Model,Accuracy,Precision,Recall,F1 Score,Average,,,Model,Scenario,Train Accuracy,Test Accuracy,Difference,
1,AdaBoost,0.60,0.47,0.60,0.50,0.54,,,Gradient Boosting,1,99%,64%,35%,32%
2,Bagging Classifier,0.48,0.42,0.48,0.45,0.46,,,,2,81%,74%,,
3,Decision Tree,0.40,0.43,0.40,0.40,0.41,,,,3,88%,52%,36%,
4,Gradient Boosting,0.50,0.47,0.50,0.47,0.49,,,,4,82%,56%,26%,
5,k-Nearest Neighbors,0.54,0.50,0.54,0.50,0.52,,,,5,83%,76%,,
6,Logistic Regression,0.60,0.63,0.60,0.59,0.61,,,k-Nearest Neighbors,1,70%,62%,,14%
7,Naïve Bayes,0.18,0.04,0.18,0.06,0.12,,,,2,71%,76%,,
8,Neural Network,0.50,0.48,0.50,0.49,0.49,,,,3,68%,54%,14%,
9,Random Forest,0.54,0.50,0.54,0.50,0.52,,,,4,72%,68%,,
10,Support Vector Machine,0.60,0.62,0.60,0.57,0.60,,,,5,70%,74%,,
,,,,,,,,,Logistic Regression,1,81%,66%,15%,15%
Scenario 4: User Affect Columns,,,,,,,,,,2,64%,72%,,
,Model,Accuracy,Precision,Recall,F1 Score,Average,,,,3,70%,60%,,
1,AdaBoost,0.46,0.62,0.46,0.46,0.50,,,,4,64%,62%,,
2,Bagging Classifier,0.58,0.66,0.58,0.60,0.60,,,,5,68%,70%,,
3,Decision Tree,0.54,0.62,0.54,0.55,0.56,,,Support Vector Machine,1,85%,72%,13%,13%
4,Gradient Boosting,0.60,0.72,0.60,0.61,0.63,,,,2,61%,72%,-11%,
5,k-Nearest Neighbors,0.72,0.71,0.72,0.70,0.71,,,,3,76%,60%,16%,
6,Logistic Regression,0.62,0.65,0.62,0.63,0.63,,,,4,72%,68%,,
7,Naïve Bayes,0.20,0.05,0.20,0.07,0.13,,,,5,75%,68%,,
8,Neural Network,0.58,0.67,0.58,0.60,0.61,,,,,,,,
9,Random Forest,0.60,0.63,0.60,0.60,0.61,,,,,,,,
10,Support Vector Machine,0.68,0.68,0.68,0.67,0.68,,,,,,,,
,,,,,,,,,,,,,,
Scenario 5: User Value Columns,,,,,,,,,,,,,,
,Model,Accuracy,Precision,Recall,F1 Score,Average,,,,,,,,
1,AdaBoost,0.44,0.65,0.44,0.47,0.50,,,,,,,,
2,Bagging Classifier,0.72,0.71,0.72,0.70,0.71,,,,,,,,
3,Decision Tree,0.64,0.64,0.64,0.64,0.64,,,,,,,,
4,Gradient Boosting,0.76,0.74,0.76,0.74,0.75,,,,,,,,
5,k-Nearest Neighbors,0.74,0.72,0.74,0.72,0.73,,,,,,,,
6,Logistic Regression,0.70,0.69,0.70,0.69,0.70,,,,,,,,
7,Naïve Bayes,0.20,0.04,0.20,0.07,0.13,,,,,,,,
8,Neural Network,0.72,0.72,0.72,0.71,0.72,,,,,,,,
9,Random Forest,0.72,0.71,0.72,0.71,0.71,,,,,,,,
10,Support Vector Machine,0.68,0.65,0.68,0.66,0.67,,,,,,,,
,,,,,,,,,,,,,,
,Support Vector Machine,0.67,,,,,,,,,,,,
,k-Nearest Neighbors,0.67,,,,,,,,,,,,
,Logistic Regression,0.66,,,,,,,,,,,,
,Gradient Boosting,0.66,,,,,,,,,,,,
,,,,,,,,,,,,,,
,Data Partition Ratio,Accuracy of Models,,,,,,,,,,,,
,,LR,DT,RF,SVM,k-NN,,,,,,,,
,"70% Training, 30% Testing",64%,56%,59%,61%,63%,,,,,,,,
,"80% Training, 20% Testing",65%,63%,65%,66%,68%,,,,,,,,
,"90% Training, 10% Testing",72%,64%,66%,72%,76%,,,,,,,,
